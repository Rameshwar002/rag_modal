
# ğŸ“˜ RAG with ChromaDB (No GPU)

This project demonstrates a **lightweight Retrieval-Augmented Generation (RAG) pipeline** using:

* [Sentence Transformers](https://www.sbert.net/) for embeddings
* [ChromaDB](https://www.trychroma.com/) as a vector database

ğŸ‘‰ Works on **CPU only** (no GPU required).

---

## ğŸš€ 1. Installation

```bash
# Create virtual environment (recommended)
python -m venv rag_env
source rag_env/bin/activate  # On Windows: rag_env\Scripts\activate

# Upgrade pip
pip install --upgrade pip

# Install dependencies
pip install chromadb sentence-transformers pandas onnxruntime
```

âš ï¸ If you see warnings like
`WARNING: The script ... is not on PATH`,
you can ignore them or add the path to your system `PATH`.

---

## ğŸ“‚ 2. Project Structure

```
rag_project/
â”‚â”€â”€ model.py
â”‚â”€â”€ model2.py          
â”‚â”€â”€ README.md          
â”‚â”€â”€ chromadb_store/    # database files (auto-created)
```

---

## ğŸ“ 3. Usage Example

```python
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings

# Embedding model
embedder = SentenceTransformer("all-MiniLM-L6-v2")

# Initialize DB (persistent storage)
client = chromadb.Client(Settings(persist_directory="./chromadb_store"))
collection = client.get_or_create_collection("documents")

# âœ… Add documents
docs = [
    "Python is a programming language.",
    "Llamas are domesticated South American camelids.",
    "ChromaDB is a vector database for AI applications."
]
embeddings = [embedder.encode(doc).tolist() for doc in docs]

collection.add(
    documents=docs,
    embeddings=embeddings,
    ids=[f"id_{i}" for i in range(len(docs))]
)

# ğŸ” Query
query = "What is ChromaDB?"
results = collection.query(
    query_embeddings=[embedder.encode(query).tolist()],
    n_results=2
)

print("Query:", query)
print("Top Results:", results["documents"])
```

---

